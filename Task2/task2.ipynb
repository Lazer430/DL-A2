{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas_datareader\n",
    "# !pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-21 08:25:13.174220: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-10-21 08:25:13.174310: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-10-21 08:25:13.175859: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-10-21 08:25:13.326672: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import pandas_datareader as pdr\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "Data Shape after load:  (2516, 7)\n"
     ]
    }
   ],
   "source": [
    "data = yf.download(\"AAPL\", start=\"2013-10-16\", end=\"2023-10-16\").reset_index()\n",
    "print(\"Data Shape after load: \", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape after cleaning:  (2516, 6)\n",
      "Data Shape after removing outliers:  (2516, 6)\n"
     ]
    }
   ],
   "source": [
    "import sklearn.preprocessing as preprocessing\n",
    "\n",
    "# data cleaning\n",
    "data = data.ffill()\n",
    "data = data.drop(['Date'], axis=1)\n",
    "#check na\n",
    "if data.isna().sum().sum() != 0:\n",
    "    print(\"There are still NA values\")\n",
    "    data = data.bfill()\n",
    "\n",
    "print(\"Data Shape after cleaning: \", data.shape)\n",
    "\n",
    "cols = ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']\n",
    "\n",
    "# perform scaling\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "data = scaler.fit_transform(data[cols])\n",
    "    \n",
    "print(\"Data Shape after removing outliers: \", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Shape:  (2509, 7, 6)\n",
      "Y Shape  (2509, 6)\n"
     ]
    }
   ],
   "source": [
    "numberOfInputDays = 7\n",
    "numberOfDaysToPredict = 1\n",
    "\n",
    "# create sequence\n",
    "def create_sequence(data, numberOfInputDays, numberOfDaysToPredict):\n",
    "    x = []\n",
    "    y = []\n",
    "    # for i in range(numberOfInputDays, data.shape[0] - numberOfDaysToPredict + 1):\n",
    "    #     x.append(data.iloc[i-numberOfInputDays:i, 1:len(cols)+1])\n",
    "    #     y.append(data.iloc[i:i+numberOfDaysToPredict][cols])\n",
    "    # return np.array(x), np.array(y)\n",
    "     \n",
    "    for i in range(len(data)-numberOfInputDays):\n",
    "        x.append(data[i:i+numberOfInputDays])\n",
    "        y.append(data[i+numberOfInputDays])\n",
    "    return np.array(x), np.array(y)\n",
    "    \n",
    "X, Y = create_sequence(data, numberOfInputDays, numberOfDaysToPredict)\n",
    "\n",
    "print(\"X Shape: \", X.shape)\n",
    "print(\"Y Shape \", Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train Shape:  (2007, 7, 6)\n",
      "Y_train Shape:  (2007, 6)\n",
      "X_test Shape:  (502, 7, 6)\n",
      "Y_test Shape:  (502, 6)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, shuffle=False, test_size=0.2)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "Y_train = np.array(Y_train)\n",
    "\n",
    "print(\"X_train Shape: \", X_train.shape)\n",
    "print(\"Y_train Shape: \", Y_train.shape)\n",
    "print(\"X_test Shape: \", X_test.shape)\n",
    "print(\"Y_test Shape: \", Y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply RNN\n",
    "def defineModel(numberOfInputDays,units):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.LSTM(units=units, input_shape=(numberOfInputDays, len(cols))))\n",
    "    model.add(keras.layers.Dropout(0.2))\n",
    "    model.add(keras.layers.Dense(units=len(cols), activation='relu'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitModelToHyperparameter(X_train, Y_train,numberOfInputDays, units, epochs, batchSize):\n",
    "    model = defineModel(numberOfInputDays, units)\n",
    "    with tf.device('/device:GPU:0'):\n",
    "        history = model.fit(X_train, Y_train, epochs=epochs, batch_size=batchSize, validation_split=0.1)\n",
    "    return model, history\n",
    "\n",
    "def gridSearch(units, epochs, batchSizes):\n",
    "    bestMSE = float('inf')\n",
    "    bestPrarams = None\n",
    "    bestModel = None\n",
    "    bestHistory = None\n",
    "    numberOfIters = len(units) * len(epochs) * len(batchSizes)\n",
    "    currentIter = 1\n",
    "    for unit in units:\n",
    "        for epoch in epochs:\n",
    "            for batchSize in batchSizes:\n",
    "                print(f\"Case : {currentIter}/{numberOfIters}\")\n",
    "                print(\"Unit: \", unit, \"Epoch: \", epoch, \"Batch Size: \", batchSize)\n",
    "                fittedModel,fittedHistory = fitModelToHyperparameter(X_train, Y_train, numberOfInputDays, unit, epoch, batchSize)\n",
    "                current_y_pred = fittedModel.predict(X_test)\n",
    "                current_y_pred = scaler.inverse_transform(current_y_pred)\n",
    "                y_actual = scaler.inverse_transform(Y_test.reshape(-1, len(cols)))\n",
    "                mean_squared_error = metrics.mean_squared_error(y_actual, current_y_pred)\n",
    "                currentIter += 1\n",
    "                \n",
    "                if mean_squared_error < bestMSE:\n",
    "                    bestMSE = mean_squared_error\n",
    "                    bestPrarams = {'units': unit, 'epochs': epoch, 'batch_size': batchSize}\n",
    "                    bestModel = fittedModel\n",
    "                    bestHistory = fittedHistory\n",
    "    print(\"Best MSE: \", bestMSE)\n",
    "    print(\"Best Params: \", bestPrarams)\n",
    "    return bestModel, bestHistory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case : 1/27\n",
      "Unit:  32 Epoch:  10 Batch Size:  16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-21 08:25:21.442484: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-21 08:25:21.482434: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-21 08:25:21.482511: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-21 08:25:21.487756: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-21 08:25:21.487870: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-21 08:25:21.487913: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-21 08:25:23.592805: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-21 08:25:23.592890: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-21 08:25:23.592900: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1977] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-10-21 08:25:23.592996: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-10-21 08:25:23.593692: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1579 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-21 08:25:29.292597: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8700\n",
      "2023-10-21 08:25:31.118666: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fdb6411e730 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-10-21 08:25:31.118741: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3050 Ti Laptop GPU, Compute Capability 8.6\n",
      "2023-10-21 08:25:31.123592: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-10-21 08:25:31.218087: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 9s 12ms/step - loss: 0.0089 - val_loss: 8.9813e-04\n",
      "Epoch 2/10\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0022 - val_loss: 9.7172e-04\n",
      "Epoch 3/10\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0018 - val_loss: 6.9127e-04\n",
      "Epoch 4/10\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 5/10\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 7.0243e-04\n",
      "Epoch 6/10\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 7/10\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 6.6696e-04\n",
      "Epoch 8/10\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 7.2462e-04\n",
      "Epoch 9/10\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 10/10\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0019\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "Case : 2/27\n",
      "Unit:  32 Epoch:  10 Batch Size:  32\n",
      "Epoch 1/10\n",
      "57/57 [==============================] - 2s 15ms/step - loss: 0.0080 - val_loss: 0.0038\n",
      "Epoch 2/10\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.0026 - val_loss: 9.5646e-04\n",
      "Epoch 3/10\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 4/10\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 5/10\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.0017 - val_loss: 5.4225e-04\n",
      "Epoch 6/10\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 7/10\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.0015 - val_loss: 3.4465e-04\n",
      "Epoch 8/10\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 3.8344e-04\n",
      "Epoch 9/10\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 10/10\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 7.4673e-04\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "Case : 3/27\n",
      "Unit:  32 Epoch:  10 Batch Size:  64\n",
      "Epoch 1/10\n",
      "29/29 [==============================] - 2s 28ms/step - loss: 0.0211 - val_loss: 0.1496\n",
      "Epoch 2/10\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.0109 - val_loss: 0.0169\n",
      "Epoch 3/10\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.0034 - val_loss: 0.0020\n",
      "Epoch 4/10\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.0023 - val_loss: 0.0011\n",
      "Epoch 5/10\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.0023 - val_loss: 5.9712e-04\n",
      "Epoch 6/10\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 5.7412e-04\n",
      "Epoch 7/10\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 5.2979e-04\n",
      "Epoch 8/10\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 3.7824e-04\n",
      "Epoch 9/10\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 3.2406e-04\n",
      "Epoch 10/10\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 4.0345e-04\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "Case : 4/27\n",
      "Unit:  32 Epoch:  20 Batch Size:  16\n",
      "Epoch 1/20\n",
      "113/113 [==============================] - 3s 11ms/step - loss: 0.0049 - val_loss: 0.0014\n",
      "Epoch 2/20\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 3/20\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0016 - val_loss: 7.1538e-04\n",
      "Epoch 4/20\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 5.7602e-04\n",
      "Epoch 5/20\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 4.8730e-04\n",
      "Epoch 6/20\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 6.7543e-04\n",
      "Epoch 7/20\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 4.9201e-04\n",
      "Epoch 8/20\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 7.8072e-04\n",
      "Epoch 9/20\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 0.0011 - val_loss: 0.0025\n",
      "Epoch 10/20\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 4.0679e-04\n",
      "Epoch 11/20\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 3.2512e-04\n",
      "Epoch 12/20\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 5.8379e-04\n",
      "Epoch 13/20\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 9.8474e-04 - val_loss: 5.6475e-04\n",
      "Epoch 14/20\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 9.3601e-04 - val_loss: 0.0011\n",
      "Epoch 15/20\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 9.9978e-04 - val_loss: 4.3436e-04\n",
      "Epoch 16/20\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 9.2267e-04 - val_loss: 7.4956e-04\n",
      "Epoch 17/20\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 9.1423e-04 - val_loss: 4.9200e-04\n",
      "Epoch 18/20\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 9.2730e-04 - val_loss: 3.1524e-04\n",
      "Epoch 19/20\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 9.0191e-04 - val_loss: 4.2281e-04\n",
      "Epoch 20/20\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 9.0289e-04 - val_loss: 4.9745e-04\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "Case : 5/27\n",
      "Unit:  32 Epoch:  20 Batch Size:  32\n",
      "Epoch 1/20\n",
      "57/57 [==============================] - 2s 15ms/step - loss: 0.0185 - val_loss: 0.0267\n",
      "Epoch 2/20\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0032 - val_loss: 0.0024\n",
      "Epoch 3/20\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0022 - val_loss: 8.2910e-04\n",
      "Epoch 4/20\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.0019 - val_loss: 5.5991e-04\n",
      "Epoch 5/20\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.0018 - val_loss: 8.3162e-04\n",
      "Epoch 6/20\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.0016 - val_loss: 9.4093e-04\n",
      "Epoch 7/20\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 8/20\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 7.7878e-04\n",
      "Epoch 9/20\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 10/20\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 8.9288e-04\n",
      "Epoch 11/20\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 7.0326e-04\n",
      "Epoch 12/20\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 13/20\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 8.0125e-04\n",
      "Epoch 14/20\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 6.9244e-04\n",
      "Epoch 15/20\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 16/20\n",
      "57/57 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 17/20\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 3.6635e-04\n",
      "Epoch 18/20\n",
      "57/57 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 4.0253e-04\n",
      "Epoch 19/20\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 8.1130e-04\n",
      "Epoch 20/20\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 6.3223e-04\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "Case : 6/27\n",
      "Unit:  32 Epoch:  20 Batch Size:  64\n",
      "Epoch 1/20\n",
      "29/29 [==============================] - 2s 21ms/step - loss: 0.0178 - val_loss: 0.0375\n",
      "Epoch 2/20\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.0043 - val_loss: 0.0027\n",
      "Epoch 3/20\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.0027 - val_loss: 0.0013\n",
      "Epoch 4/20\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.0023 - val_loss: 9.9898e-04\n",
      "Epoch 5/20\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.0022 - val_loss: 7.5591e-04\n",
      "Epoch 6/20\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 5.0419e-04\n",
      "Epoch 7/20\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.0019 - val_loss: 5.1515e-04\n",
      "Epoch 8/20\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 4.4739e-04\n",
      "Epoch 9/20\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 3.3180e-04\n",
      "Epoch 10/20\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 5.1443e-04\n",
      "Epoch 11/20\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 5.4525e-04\n",
      "Epoch 12/20\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 3.2850e-04\n",
      "Epoch 13/20\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 3.2986e-04\n",
      "Epoch 14/20\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 5.3393e-04\n",
      "Epoch 15/20\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 3.8316e-04\n",
      "Epoch 16/20\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 7.6253e-04\n",
      "Epoch 17/20\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 5.0576e-04\n",
      "Epoch 18/20\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 7.3356e-04\n",
      "Epoch 19/20\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 3.8322e-04\n",
      "Epoch 20/20\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 6.0432e-04\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "Case : 7/27\n",
      "Unit:  32 Epoch:  30 Batch Size:  16\n",
      "Epoch 1/30\n",
      "113/113 [==============================] - 3s 11ms/step - loss: 0.0079 - val_loss: 0.0015\n",
      "Epoch 2/30\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0020 - val_loss: 6.1192e-04\n",
      "Epoch 3/30\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0017 - val_loss: 4.7483e-04\n",
      "Epoch 4/30\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 8.2670e-04\n",
      "Epoch 5/30\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 6/30\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 4.0959e-04\n",
      "Epoch 7/30\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 8/30\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 6.6335e-04\n",
      "Epoch 9/30\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 5.9223e-04\n",
      "Epoch 10/30\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 11/30\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 7.4475e-04\n",
      "Epoch 12/30\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 9.9678e-04 - val_loss: 8.8570e-04\n",
      "Epoch 13/30\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 0.0010 - val_loss: 4.4588e-04\n",
      "Epoch 14/30\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 9.8668e-04 - val_loss: 5.8423e-04\n",
      "Epoch 15/30\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 9.6153e-04 - val_loss: 4.8406e-04\n",
      "Epoch 16/30\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 9.8500e-04 - val_loss: 5.0515e-04\n",
      "Epoch 17/30\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 9.4019e-04 - val_loss: 4.3545e-04\n",
      "Epoch 18/30\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 9.2565e-04 - val_loss: 0.0010\n",
      "Epoch 19/30\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 9.2383e-04 - val_loss: 7.3980e-04\n",
      "Epoch 20/30\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 9.3025e-04 - val_loss: 6.9741e-04\n",
      "Epoch 21/30\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 9.0772e-04 - val_loss: 3.4552e-04\n",
      "Epoch 22/30\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 8.9699e-04 - val_loss: 7.4015e-04\n",
      "Epoch 23/30\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 9.2187e-04 - val_loss: 6.6638e-04\n",
      "Epoch 24/30\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 9.3253e-04 - val_loss: 2.8199e-04\n",
      "Epoch 25/30\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 9.0697e-04 - val_loss: 3.5127e-04\n",
      "Epoch 26/30\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 8.8731e-04 - val_loss: 4.6413e-04\n",
      "Epoch 27/30\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 9.2039e-04 - val_loss: 3.3302e-04\n",
      "Epoch 28/30\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 8.8188e-04 - val_loss: 5.9115e-04\n",
      "Epoch 29/30\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 8.4285e-04 - val_loss: 5.9177e-04\n",
      "Epoch 30/30\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 8.8288e-04 - val_loss: 6.6974e-04\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "Case : 8/27\n",
      "Unit:  32 Epoch:  30 Batch Size:  32\n",
      "Epoch 1/30\n",
      "57/57 [==============================] - 2s 14ms/step - loss: 0.0088 - val_loss: 0.0029\n",
      "Epoch 2/30\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.0027 - val_loss: 0.0016\n",
      "Epoch 3/30\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 4/30\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.0018 - val_loss: 7.3767e-04\n",
      "Epoch 5/30\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 9.5167e-04\n",
      "Epoch 6/30\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 7.1423e-04\n",
      "Epoch 7/30\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 8/30\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 9/30\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 0.0013 - val_loss: 6.7144e-04\n",
      "Epoch 10/30\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.0013 - val_loss: 4.1409e-04\n",
      "Epoch 11/30\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 8.1091e-04\n",
      "Epoch 12/30\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 6.4374e-04\n",
      "Epoch 13/30\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 14/30\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 3.7120e-04\n",
      "Epoch 15/30\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 4.5931e-04\n",
      "Epoch 16/30\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 8.2600e-04\n",
      "Epoch 17/30\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 6.5643e-04\n",
      "Epoch 18/30\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 4.9547e-04\n",
      "Epoch 19/30\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 9.0023e-04\n",
      "Epoch 20/30\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 9.7955e-04 - val_loss: 6.9295e-04\n",
      "Epoch 21/30\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 9.5373e-04 - val_loss: 4.0797e-04\n",
      "Epoch 22/30\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.9238e-04 - val_loss: 4.8994e-04\n",
      "Epoch 23/30\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 24/30\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 9.6916e-04 - val_loss: 5.2852e-04\n",
      "Epoch 25/30\n",
      "57/57 [==============================] - 0s 8ms/step - loss: 9.9238e-04 - val_loss: 4.4437e-04\n",
      "Epoch 26/30\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 9.5378e-04 - val_loss: 8.9617e-04\n",
      "Epoch 27/30\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 9.4830e-04 - val_loss: 3.0429e-04\n",
      "Epoch 28/30\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 9.3009e-04 - val_loss: 4.1681e-04\n",
      "Epoch 29/30\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.2103e-04 - val_loss: 4.8873e-04\n",
      "Epoch 30/30\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.2244e-04 - val_loss: 4.8880e-04\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "Case : 9/27\n",
      "Unit:  32 Epoch:  30 Batch Size:  64\n",
      "Epoch 1/30\n",
      "29/29 [==============================] - 2s 20ms/step - loss: 0.0121 - val_loss: 0.0046\n",
      "Epoch 2/30\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.0029 - val_loss: 0.0014\n",
      "Epoch 3/30\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.0023 - val_loss: 0.0010\n",
      "Epoch 4/30\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 5/30\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 9.0997e-04\n",
      "Epoch 6/30\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 5.7584e-04\n",
      "Epoch 7/30\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 5.9156e-04\n",
      "Epoch 8/30\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 9/30\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 10/30\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 4.2966e-04\n",
      "Epoch 11/30\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 6.6366e-04\n",
      "Epoch 12/30\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 5.4402e-04\n",
      "Epoch 13/30\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 5.0520e-04\n",
      "Epoch 14/30\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 8.4860e-04\n",
      "Epoch 15/30\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 7.7013e-04\n",
      "Epoch 16/30\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 6.0643e-04\n",
      "Epoch 17/30\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 4.4460e-04\n",
      "Epoch 18/30\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 7.2452e-04\n",
      "Epoch 19/30\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 20/30\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 8.4985e-04\n",
      "Epoch 21/30\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 22/30\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 7.4846e-04\n",
      "Epoch 23/30\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 5.2967e-04\n",
      "Epoch 24/30\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 5.7079e-04\n",
      "Epoch 25/30\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 5.1329e-04\n",
      "Epoch 26/30\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 6.4594e-04\n",
      "Epoch 27/30\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 9.5187e-04\n",
      "Epoch 28/30\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 3.8696e-04\n",
      "Epoch 29/30\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 9.8189e-04 - val_loss: 4.9371e-04\n",
      "Epoch 30/30\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 9.9548e-04 - val_loss: 8.6274e-04\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "Case : 10/27\n",
      "Unit:  64 Epoch:  10 Batch Size:  16\n",
      "Epoch 1/10\n",
      "113/113 [==============================] - 3s 12ms/step - loss: 0.0048 - val_loss: 0.0011\n",
      "Epoch 2/10\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0015 - val_loss: 3.8184e-04\n",
      "Epoch 3/10\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 6.2744e-04\n",
      "Epoch 4/10\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 7.8869e-04\n",
      "Epoch 5/10\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 8.6838e-04\n",
      "Epoch 6/10\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 6.0197e-04\n",
      "Epoch 7/10\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 5.2645e-04\n",
      "Epoch 8/10\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 9.7718e-04 - val_loss: 4.5698e-04\n",
      "Epoch 9/10\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 9.7854e-04 - val_loss: 6.0662e-04\n",
      "Epoch 10/10\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 9.1075e-04 - val_loss: 0.0011\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "Case : 11/27\n",
      "Unit:  64 Epoch:  10 Batch Size:  32\n",
      "Epoch 1/10\n",
      "57/57 [==============================] - 2s 15ms/step - loss: 0.0066 - val_loss: 0.0010\n",
      "Epoch 2/10\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.0018 - val_loss: 7.1245e-04\n",
      "Epoch 3/10\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.0016 - val_loss: 8.0933e-04\n",
      "Epoch 4/10\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 6.3543e-04\n",
      "Epoch 5/10\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 4.4565e-04\n",
      "Epoch 6/10\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 6.3129e-04\n",
      "Epoch 7/10\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 5.8764e-04\n",
      "Epoch 8/10\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0011 - val_loss: 3.6492e-04\n",
      "Epoch 9/10\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0011 - val_loss: 3.0960e-04\n",
      "Epoch 10/10\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.8238e-04 - val_loss: 5.8429e-04\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "Case : 12/27\n",
      "Unit:  64 Epoch:  10 Batch Size:  64\n",
      "Epoch 1/10\n",
      "29/29 [==============================] - 2s 21ms/step - loss: 0.0130 - val_loss: 0.0304\n",
      "Epoch 2/10\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 3/10\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 5.7419e-04\n",
      "Epoch 4/10\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 5.4081e-04\n",
      "Epoch 5/10\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 6.3326e-04\n",
      "Epoch 6/10\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 5.1509e-04\n",
      "Epoch 7/10\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 5.8069e-04\n",
      "Epoch 8/10\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 6.0260e-04\n",
      "Epoch 9/10\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 9.6949e-04\n",
      "Epoch 10/10\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 4.2293e-04\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "Case : 13/27\n",
      "Unit:  64 Epoch:  20 Batch Size:  16\n",
      "Epoch 1/20\n",
      "113/113 [==============================] - 3s 12ms/step - loss: 0.0046 - val_loss: 5.5585e-04\n",
      "Epoch 2/20\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0016 - val_loss: 7.5148e-04\n",
      "Epoch 3/20\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 4/20\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 5.4871e-04\n",
      "Epoch 5/20\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 9.0720e-04\n",
      "Epoch 6/20\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 8.7445e-04\n",
      "Epoch 7/20\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 9.9196e-04 - val_loss: 4.0716e-04\n",
      "Epoch 8/20\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 9.7594e-04 - val_loss: 7.0534e-04\n",
      "Epoch 9/20\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 9.2737e-04 - val_loss: 5.8265e-04\n",
      "Epoch 10/20\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 9.3181e-04 - val_loss: 9.2836e-04\n",
      "Epoch 11/20\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 8.9836e-04 - val_loss: 8.0831e-04\n",
      "Epoch 12/20\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 8.9989e-04 - val_loss: 6.6774e-04\n",
      "Epoch 13/20\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 8.7837e-04 - val_loss: 7.0625e-04\n",
      "Epoch 14/20\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 9.2333e-04 - val_loss: 6.5244e-04\n",
      "Epoch 15/20\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 8.6682e-04 - val_loss: 6.1489e-04\n",
      "Epoch 16/20\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 8.2590e-04 - val_loss: 4.4176e-04\n",
      "Epoch 17/20\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 8.3345e-04 - val_loss: 4.3944e-04\n",
      "Epoch 18/20\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 7.9204e-04 - val_loss: 0.0016\n",
      "Epoch 19/20\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 8.1192e-04 - val_loss: 8.4655e-04\n",
      "Epoch 20/20\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 8.1129e-04 - val_loss: 0.0012\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "Case : 14/27\n",
      "Unit:  64 Epoch:  20 Batch Size:  32\n",
      "Epoch 1/20\n",
      "57/57 [==============================] - 2s 14ms/step - loss: 0.0064 - val_loss: 0.0015\n",
      "Epoch 2/20\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.0016 - val_loss: 3.7643e-04\n",
      "Epoch 3/20\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 3.9255e-04\n",
      "Epoch 4/20\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 4.7310e-04\n",
      "Epoch 5/20\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 9.0166e-04\n",
      "Epoch 6/20\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 4.4555e-04\n",
      "Epoch 7/20\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 6.4717e-04\n",
      "Epoch 8/20\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 9/20\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 3.5467e-04\n",
      "Epoch 10/20\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 9.8492e-04 - val_loss: 3.7168e-04\n",
      "Epoch 11/20\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.9453e-04 - val_loss: 6.1994e-04\n",
      "Epoch 12/20\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.3380e-04 - val_loss: 3.0615e-04\n",
      "Epoch 13/20\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 9.3046e-04 - val_loss: 5.9975e-04\n",
      "Epoch 14/20\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 9.3650e-04 - val_loss: 7.0620e-04\n",
      "Epoch 15/20\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.2557e-04 - val_loss: 0.0011\n",
      "Epoch 16/20\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.8945e-04 - val_loss: 3.4915e-04\n",
      "Epoch 17/20\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.2082e-04 - val_loss: 4.8571e-04\n",
      "Epoch 18/20\n",
      "57/57 [==============================] - 0s 9ms/step - loss: 8.9240e-04 - val_loss: 6.8429e-04\n",
      "Epoch 19/20\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.7216e-04 - val_loss: 4.8112e-04\n",
      "Epoch 20/20\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.4632e-04 - val_loss: 0.0010\n",
      "16/16 [==============================] - 1s 4ms/step\n",
      "Case : 15/27\n",
      "Unit:  64 Epoch:  20 Batch Size:  64\n",
      "Epoch 1/20\n",
      "29/29 [==============================] - 2s 21ms/step - loss: 0.0190 - val_loss: 0.0770\n",
      "Epoch 2/20\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.0056 - val_loss: 7.5134e-04\n",
      "Epoch 3/20\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 4/20\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 4.6261e-04\n",
      "Epoch 5/20\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 8.2795e-04\n",
      "Epoch 6/20\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 6.0122e-04\n",
      "Epoch 7/20\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 5.7911e-04\n",
      "Epoch 8/20\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 5.2717e-04\n",
      "Epoch 9/20\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 8.7095e-04\n",
      "Epoch 10/20\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 11/20\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 5.4299e-04\n",
      "Epoch 12/20\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 6.4051e-04\n",
      "Epoch 13/20\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 7.7254e-04\n",
      "Epoch 14/20\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 8.9921e-04\n",
      "Epoch 15/20\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 6.0754e-04\n",
      "Epoch 16/20\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 7.4639e-04\n",
      "Epoch 17/20\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 7.8490e-04\n",
      "Epoch 18/20\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 4.1917e-04\n",
      "Epoch 19/20\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 9.7823e-04 - val_loss: 4.3416e-04\n",
      "Epoch 20/20\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 9.9622e-04 - val_loss: 5.6315e-04\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "Case : 16/27\n",
      "Unit:  64 Epoch:  30 Batch Size:  16\n",
      "Epoch 1/30\n",
      "113/113 [==============================] - 3s 11ms/step - loss: 0.0036 - val_loss: 6.5258e-04\n",
      "Epoch 2/30\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 3.7350e-04\n",
      "Epoch 3/30\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 4.2177e-04\n",
      "Epoch 4/30\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 6.4645e-04\n",
      "Epoch 5/30\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 6/30\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 8.5276e-04\n",
      "Epoch 7/30\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 7.9438e-04\n",
      "Epoch 8/30\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 9.7901e-04 - val_loss: 0.0011\n",
      "Epoch 9/30\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 9.3498e-04 - val_loss: 7.9968e-04\n",
      "Epoch 10/30\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 8.9896e-04 - val_loss: 9.6709e-04\n",
      "Epoch 11/30\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 8.6228e-04 - val_loss: 4.3931e-04\n",
      "Epoch 12/30\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 8.8737e-04 - val_loss: 5.6117e-04\n",
      "Epoch 13/30\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 8.6414e-04 - val_loss: 2.8065e-04\n",
      "Epoch 14/30\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 8.4808e-04 - val_loss: 5.7606e-04\n",
      "Epoch 15/30\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 8.3450e-04 - val_loss: 4.8209e-04\n",
      "Epoch 16/30\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 8.0442e-04 - val_loss: 4.5731e-04\n",
      "Epoch 17/30\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 8.1851e-04 - val_loss: 3.9306e-04\n",
      "Epoch 18/30\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 7.8739e-04 - val_loss: 3.7780e-04\n",
      "Epoch 19/30\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 8.1420e-04 - val_loss: 3.8978e-04\n",
      "Epoch 20/30\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 7.9168e-04 - val_loss: 6.9781e-04\n",
      "Epoch 21/30\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 7.7425e-04 - val_loss: 4.8103e-04\n",
      "Epoch 22/30\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 7.9386e-04 - val_loss: 3.3653e-04\n",
      "Epoch 23/30\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 7.6167e-04 - val_loss: 4.8400e-04\n",
      "Epoch 24/30\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 8.1236e-04 - val_loss: 4.8248e-04\n",
      "Epoch 25/30\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 7.9729e-04 - val_loss: 8.8514e-04\n",
      "Epoch 26/30\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 7.6056e-04 - val_loss: 9.4115e-04\n",
      "Epoch 27/30\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 8.1315e-04 - val_loss: 5.7702e-04\n",
      "Epoch 28/30\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 7.8027e-04 - val_loss: 6.1858e-04\n",
      "Epoch 29/30\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 7.9603e-04 - val_loss: 2.7869e-04\n",
      "Epoch 30/30\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 7.5003e-04 - val_loss: 9.6882e-04\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "Case : 17/27\n",
      "Unit:  64 Epoch:  30 Batch Size:  32\n",
      "Epoch 1/30\n",
      "57/57 [==============================] - 2s 15ms/step - loss: 0.0055 - val_loss: 0.0010\n",
      "Epoch 2/30\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 3/30\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.0015 - val_loss: 7.5031e-04\n",
      "Epoch 4/30\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.0014 - val_loss: 4.0055e-04\n",
      "Epoch 5/30\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.0013 - val_loss: 5.6357e-04\n",
      "Epoch 6/30\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 8.2257e-04\n",
      "Epoch 7/30\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 4.1163e-04\n",
      "Epoch 8/30\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 6.2989e-04\n",
      "Epoch 9/30\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0011 - val_loss: 4.1643e-04\n",
      "Epoch 10/30\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 4.6403e-04\n",
      "Epoch 11/30\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 8.2628e-04\n",
      "Epoch 12/30\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.5920e-04 - val_loss: 7.6410e-04\n",
      "Epoch 13/30\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.6886e-04 - val_loss: 9.5036e-04\n",
      "Epoch 14/30\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 9.4268e-04 - val_loss: 5.3766e-04\n",
      "Epoch 15/30\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.8263e-04 - val_loss: 4.7861e-04\n",
      "Epoch 16/30\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.9915e-04 - val_loss: 3.0737e-04\n",
      "Epoch 17/30\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.7706e-04 - val_loss: 3.8346e-04\n",
      "Epoch 18/30\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.5524e-04 - val_loss: 2.6619e-04\n",
      "Epoch 19/30\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.7811e-04 - val_loss: 3.4358e-04\n",
      "Epoch 20/30\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.6338e-04 - val_loss: 3.6194e-04\n",
      "Epoch 21/30\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.6649e-04 - val_loss: 3.3630e-04\n",
      "Epoch 22/30\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.4509e-04 - val_loss: 3.5786e-04\n",
      "Epoch 23/30\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.3324e-04 - val_loss: 8.7041e-04\n",
      "Epoch 24/30\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.2287e-04 - val_loss: 6.6165e-04\n",
      "Epoch 25/30\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.0087e-04 - val_loss: 4.4710e-04\n",
      "Epoch 26/30\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.0983e-04 - val_loss: 5.6017e-04\n",
      "Epoch 27/30\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.3794e-04 - val_loss: 5.2740e-04\n",
      "Epoch 28/30\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.3742e-04 - val_loss: 4.3922e-04\n",
      "Epoch 29/30\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 7.9670e-04 - val_loss: 4.3805e-04\n",
      "Epoch 30/30\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.1704e-04 - val_loss: 7.1896e-04\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "Case : 18/27\n",
      "Unit:  64 Epoch:  30 Batch Size:  64\n",
      "Epoch 1/30\n",
      "29/29 [==============================] - 2s 22ms/step - loss: 0.0136 - val_loss: 0.0058\n",
      "Epoch 2/30\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 3/30\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 6.1218e-04\n",
      "Epoch 4/30\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 6.1242e-04\n",
      "Epoch 5/30\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 4.1906e-04\n",
      "Epoch 6/30\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 4.7471e-04\n",
      "Epoch 7/30\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 4.8422e-04\n",
      "Epoch 8/30\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0014 - val_loss: 6.6105e-04\n",
      "Epoch 9/30\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 3.7830e-04\n",
      "Epoch 10/30\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 5.4147e-04\n",
      "Epoch 11/30\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 4.1425e-04\n",
      "Epoch 12/30\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 7.8711e-04\n",
      "Epoch 13/30\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0012 - val_loss: 4.1649e-04\n",
      "Epoch 14/30\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 4.8226e-04\n",
      "Epoch 15/30\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 3.4821e-04\n",
      "Epoch 16/30\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 4.2216e-04\n",
      "Epoch 17/30\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 9.6611e-04\n",
      "Epoch 18/30\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0010 - val_loss: 3.9263e-04\n",
      "Epoch 19/30\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0010 - val_loss: 3.4632e-04\n",
      "Epoch 20/30\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 4.4099e-04\n",
      "Epoch 21/30\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 9.7545e-04 - val_loss: 3.1694e-04\n",
      "Epoch 22/30\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 9.8474e-04 - val_loss: 3.8220e-04\n",
      "Epoch 23/30\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 9.9132e-04 - val_loss: 7.0368e-04\n",
      "Epoch 24/30\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 9.5104e-04 - val_loss: 5.4266e-04\n",
      "Epoch 25/30\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 9.4178e-04 - val_loss: 5.2699e-04\n",
      "Epoch 26/30\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 8.9945e-04 - val_loss: 8.1790e-04\n",
      "Epoch 27/30\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 9.3811e-04 - val_loss: 0.0015\n",
      "Epoch 28/30\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 9.1742e-04 - val_loss: 7.9577e-04\n",
      "Epoch 29/30\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 9.2479e-04 - val_loss: 3.6502e-04\n",
      "Epoch 30/30\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 8.8843e-04 - val_loss: 5.0560e-04\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "Case : 19/27\n",
      "Unit:  128 Epoch:  10 Batch Size:  16\n",
      "Epoch 1/10\n",
      "113/113 [==============================] - 3s 12ms/step - loss: 0.0040 - val_loss: 0.0011\n",
      "Epoch 2/10\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 4.4935e-04\n",
      "Epoch 3/10\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 4/10\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 5/10\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 9.9701e-04 - val_loss: 0.0031\n",
      "Epoch 6/10\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 9.6712e-04 - val_loss: 0.0011\n",
      "Epoch 7/10\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 8.8154e-04 - val_loss: 0.0011\n",
      "Epoch 8/10\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 8.6985e-04 - val_loss: 0.0010\n",
      "Epoch 9/10\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 8.3857e-04 - val_loss: 5.8129e-04\n",
      "Epoch 10/10\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 8.3353e-04 - val_loss: 4.4824e-04\n",
      "16/16 [==============================] - 1s 5ms/step\n",
      "Case : 20/27\n",
      "Unit:  128 Epoch:  10 Batch Size:  32\n",
      "Epoch 1/10\n",
      "57/57 [==============================] - 2s 15ms/step - loss: 0.0106 - val_loss: 0.0013\n",
      "Epoch 2/10\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0013 - val_loss: 6.5427e-04\n",
      "Epoch 3/10\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 4/10\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0011 - val_loss: 5.7014e-04\n",
      "Epoch 5/10\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0011 - val_loss: 7.3590e-04\n",
      "Epoch 6/10\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 9.8346e-04 - val_loss: 6.2106e-04\n",
      "Epoch 7/10\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 9.7240e-04 - val_loss: 0.0011\n",
      "Epoch 8/10\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 9.7412e-04 - val_loss: 5.8161e-04\n",
      "Epoch 9/10\n",
      "57/57 [==============================] - 1s 9ms/step - loss: 8.9702e-04 - val_loss: 4.2608e-04\n",
      "Epoch 10/10\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 9.0831e-04 - val_loss: 4.2579e-04\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "Case : 21/27\n",
      "Unit:  128 Epoch:  10 Batch Size:  64\n",
      "Epoch 1/10\n",
      "29/29 [==============================] - 2s 22ms/step - loss: 0.0078 - val_loss: 0.0028\n",
      "Epoch 2/10\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 3/10\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0014 - val_loss: 9.8339e-04\n",
      "Epoch 4/10\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 4.4986e-04\n",
      "Epoch 5/10\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 6/10\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 5.4007e-04\n",
      "Epoch 7/10\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 6.9387e-04\n",
      "Epoch 8/10\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 4.8434e-04\n",
      "Epoch 9/10\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0010 - val_loss: 6.2048e-04\n",
      "Epoch 10/10\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 9.7734e-04 - val_loss: 0.0014\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "Case : 22/27\n",
      "Unit:  128 Epoch:  20 Batch Size:  16\n",
      "Epoch 1/20\n",
      "113/113 [==============================] - 3s 12ms/step - loss: 0.0033 - val_loss: 0.0019\n",
      "Epoch 2/20\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0012 - val_loss: 7.0176e-04\n",
      "Epoch 3/20\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 9.1895e-04\n",
      "Epoch 4/20\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 5/20\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 9.7942e-04 - val_loss: 5.1941e-04\n",
      "Epoch 6/20\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 9.2527e-04 - val_loss: 6.2469e-04\n",
      "Epoch 7/20\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 9.0105e-04 - val_loss: 0.0013\n",
      "Epoch 8/20\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 8.7598e-04 - val_loss: 6.3504e-04\n",
      "Epoch 9/20\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 8.8180e-04 - val_loss: 0.0011\n",
      "Epoch 10/20\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 8.2753e-04 - val_loss: 0.0021\n",
      "Epoch 11/20\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 7.9600e-04 - val_loss: 4.3718e-04\n",
      "Epoch 12/20\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 8.0249e-04 - val_loss: 5.3669e-04\n",
      "Epoch 13/20\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 8.1277e-04 - val_loss: 3.3456e-04\n",
      "Epoch 14/20\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 7.9436e-04 - val_loss: 9.3863e-04\n",
      "Epoch 15/20\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 7.8747e-04 - val_loss: 9.2121e-04\n",
      "Epoch 16/20\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 7.9635e-04 - val_loss: 8.0845e-04\n",
      "Epoch 17/20\n",
      "113/113 [==============================] - 1s 8ms/step - loss: 7.7797e-04 - val_loss: 6.6159e-04\n",
      "Epoch 18/20\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 7.4187e-04 - val_loss: 3.5429e-04\n",
      "Epoch 19/20\n",
      "113/113 [==============================] - 1s 9ms/step - loss: 7.6622e-04 - val_loss: 2.8234e-04\n",
      "Epoch 20/20\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 7.7049e-04 - val_loss: 0.0021\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "Case : 23/27\n",
      "Unit:  128 Epoch:  20 Batch Size:  32\n",
      "Epoch 1/20\n",
      "57/57 [==============================] - 2s 16ms/step - loss: 0.0046 - val_loss: 0.0012\n",
      "Epoch 2/20\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0012 - val_loss: 5.5569e-04\n",
      "Epoch 3/20\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0012 - val_loss: 5.5952e-04\n",
      "Epoch 4/20\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0011 - val_loss: 4.1298e-04\n",
      "Epoch 5/20\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0011 - val_loss: 5.0052e-04\n",
      "Epoch 6/20\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0010 - val_loss: 4.8209e-04\n",
      "Epoch 7/20\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 9.6591e-04 - val_loss: 4.7204e-04\n",
      "Epoch 8/20\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 9.1546e-04 - val_loss: 7.1105e-04\n",
      "Epoch 9/20\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 9.1815e-04 - val_loss: 4.0691e-04\n",
      "Epoch 10/20\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 9.0957e-04 - val_loss: 0.0010\n",
      "Epoch 11/20\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 8.9672e-04 - val_loss: 6.8563e-04\n",
      "Epoch 12/20\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 8.5040e-04 - val_loss: 5.2116e-04\n",
      "Epoch 13/20\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 8.5425e-04 - val_loss: 9.4099e-04\n",
      "Epoch 14/20\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 8.6723e-04 - val_loss: 8.4846e-04\n",
      "Epoch 15/20\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 8.5050e-04 - val_loss: 9.2016e-04\n",
      "Epoch 16/20\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 8.5607e-04 - val_loss: 0.0010\n",
      "Epoch 17/20\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 8.0694e-04 - val_loss: 0.0011\n",
      "Epoch 18/20\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 8.1994e-04 - val_loss: 4.9957e-04\n",
      "Epoch 19/20\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 7.7321e-04 - val_loss: 8.9677e-04\n",
      "Epoch 20/20\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 7.8054e-04 - val_loss: 2.5868e-04\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "Case : 24/27\n",
      "Unit:  128 Epoch:  20 Batch Size:  64\n",
      "Epoch 1/20\n",
      "29/29 [==============================] - 2s 23ms/step - loss: 0.0092 - val_loss: 0.0013\n",
      "Epoch 2/20\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0017 - val_loss: 8.9069e-04\n",
      "Epoch 3/20\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0014 - val_loss: 3.7160e-04\n",
      "Epoch 4/20\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 4.6169e-04\n",
      "Epoch 5/20\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0012 - val_loss: 3.7009e-04\n",
      "Epoch 6/20\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 5.0584e-04\n",
      "Epoch 7/20\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 8.7545e-04\n",
      "Epoch 8/20\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 7.0634e-04\n",
      "Epoch 9/20\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 4.2703e-04\n",
      "Epoch 10/20\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 0.0010 - val_loss: 5.7672e-04\n",
      "Epoch 11/20\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 9.9331e-04 - val_loss: 4.7704e-04\n",
      "Epoch 12/20\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 9.8980e-04 - val_loss: 4.0419e-04\n",
      "Epoch 13/20\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 9.4534e-04 - val_loss: 9.3370e-04\n",
      "Epoch 14/20\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 9.3487e-04 - val_loss: 3.2876e-04\n",
      "Epoch 15/20\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 9.7128e-04 - val_loss: 3.7508e-04\n",
      "Epoch 16/20\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 9.3984e-04 - val_loss: 3.7131e-04\n",
      "Epoch 17/20\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 9.3648e-04 - val_loss: 3.6803e-04\n",
      "Epoch 18/20\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 8.8862e-04 - val_loss: 7.1153e-04\n",
      "Epoch 19/20\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 8.8235e-04 - val_loss: 4.4280e-04\n",
      "Epoch 20/20\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 8.4487e-04 - val_loss: 4.3839e-04\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "Case : 25/27\n",
      "Unit:  128 Epoch:  30 Batch Size:  16\n",
      "Epoch 1/30\n",
      "113/113 [==============================] - 4s 13ms/step - loss: 0.0041 - val_loss: 6.8553e-04\n",
      "Epoch 2/30\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.0012 - val_loss: 4.7805e-04\n",
      "Epoch 3/30\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.0011 - val_loss: 9.1626e-04\n",
      "Epoch 4/30\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 0.0010 - val_loss: 7.7506e-04\n",
      "Epoch 5/30\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 9.7681e-04 - val_loss: 0.0013\n",
      "Epoch 6/30\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 9.9026e-04 - val_loss: 0.0018\n",
      "Epoch 7/30\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 8.7897e-04 - val_loss: 6.7647e-04\n",
      "Epoch 8/30\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 8.6024e-04 - val_loss: 0.0011\n",
      "Epoch 9/30\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 8.4094e-04 - val_loss: 9.7544e-04\n",
      "Epoch 10/30\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 8.3685e-04 - val_loss: 5.8144e-04\n",
      "Epoch 11/30\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 8.2583e-04 - val_loss: 7.6266e-04\n",
      "Epoch 12/30\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 7.9915e-04 - val_loss: 0.0017\n",
      "Epoch 13/30\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 7.7630e-04 - val_loss: 7.7984e-04\n",
      "Epoch 14/30\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 7.8828e-04 - val_loss: 5.2605e-04\n",
      "Epoch 15/30\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 7.8889e-04 - val_loss: 3.2748e-04\n",
      "Epoch 16/30\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 7.7158e-04 - val_loss: 0.0015\n",
      "Epoch 17/30\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 7.6104e-04 - val_loss: 3.1186e-04\n",
      "Epoch 18/30\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 7.6471e-04 - val_loss: 2.3011e-04\n",
      "Epoch 19/30\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 7.6086e-04 - val_loss: 3.1714e-04\n",
      "Epoch 20/30\n",
      "113/113 [==============================] - 1s 11ms/step - loss: 7.5889e-04 - val_loss: 5.3264e-04\n",
      "Epoch 21/30\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 7.3568e-04 - val_loss: 9.7377e-04\n",
      "Epoch 22/30\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 7.3848e-04 - val_loss: 8.4709e-04\n",
      "Epoch 23/30\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 7.4043e-04 - val_loss: 4.9716e-04\n",
      "Epoch 24/30\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 7.2884e-04 - val_loss: 5.0012e-04\n",
      "Epoch 25/30\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 7.2948e-04 - val_loss: 9.0699e-04\n",
      "Epoch 26/30\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 7.2180e-04 - val_loss: 4.0050e-04\n",
      "Epoch 27/30\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 7.1431e-04 - val_loss: 0.0010\n",
      "Epoch 28/30\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 7.0783e-04 - val_loss: 2.0380e-04\n",
      "Epoch 29/30\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 7.1829e-04 - val_loss: 2.1437e-04\n",
      "Epoch 30/30\n",
      "113/113 [==============================] - 1s 10ms/step - loss: 7.2030e-04 - val_loss: 5.9608e-04\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "Case : 26/27\n",
      "Unit:  128 Epoch:  30 Batch Size:  32\n",
      "Epoch 1/30\n",
      "57/57 [==============================] - 2s 15ms/step - loss: 0.0086 - val_loss: 0.0021\n",
      "Epoch 2/30\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 3/30\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 4/30\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 5/30\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0011 - val_loss: 0.0034\n",
      "Epoch 6/30\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 0.0011 - val_loss: 5.9705e-04\n",
      "Epoch 7/30\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 9.9436e-04 - val_loss: 0.0011\n",
      "Epoch 8/30\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 9.6645e-04 - val_loss: 5.7404e-04\n",
      "Epoch 9/30\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 9.3213e-04 - val_loss: 4.2264e-04\n",
      "Epoch 10/30\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 9.3276e-04 - val_loss: 6.9598e-04\n",
      "Epoch 11/30\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 9.2472e-04 - val_loss: 4.3764e-04\n",
      "Epoch 12/30\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 9.1146e-04 - val_loss: 7.5755e-04\n",
      "Epoch 13/30\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 9.0206e-04 - val_loss: 0.0015\n",
      "Epoch 14/30\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 9.0130e-04 - val_loss: 7.8493e-04\n",
      "Epoch 15/30\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 8.1777e-04 - val_loss: 5.5430e-04\n",
      "Epoch 16/30\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 8.4324e-04 - val_loss: 3.4436e-04\n",
      "Epoch 17/30\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 8.2338e-04 - val_loss: 4.9767e-04\n",
      "Epoch 18/30\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 8.2577e-04 - val_loss: 3.7904e-04\n",
      "Epoch 19/30\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 8.0244e-04 - val_loss: 4.2729e-04\n",
      "Epoch 20/30\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 8.1992e-04 - val_loss: 3.3711e-04\n",
      "Epoch 21/30\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 7.8875e-04 - val_loss: 4.6684e-04\n",
      "Epoch 22/30\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 7.8356e-04 - val_loss: 6.9557e-04\n",
      "Epoch 23/30\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 7.9826e-04 - val_loss: 8.0548e-04\n",
      "Epoch 24/30\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 7.7108e-04 - val_loss: 8.4424e-04\n",
      "Epoch 25/30\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 7.8907e-04 - val_loss: 3.1590e-04\n",
      "Epoch 26/30\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 7.2209e-04 - val_loss: 5.4843e-04\n",
      "Epoch 27/30\n",
      "57/57 [==============================] - 1s 11ms/step - loss: 7.4983e-04 - val_loss: 7.9932e-04\n",
      "Epoch 28/30\n",
      "57/57 [==============================] - 1s 10ms/step - loss: 7.5012e-04 - val_loss: 8.0358e-04\n",
      "Epoch 29/30\n",
      "57/57 [==============================] - 1s 12ms/step - loss: 7.8644e-04 - val_loss: 5.1728e-04\n",
      "Epoch 30/30\n",
      "57/57 [==============================] - 1s 17ms/step - loss: 7.6322e-04 - val_loss: 4.7606e-04\n",
      "16/16 [==============================] - 0s 6ms/step\n",
      "Case : 27/27\n",
      "Unit:  128 Epoch:  30 Batch Size:  64\n",
      "Epoch 1/30\n",
      "29/29 [==============================] - 3s 28ms/step - loss: 0.0135 - val_loss: 0.0748\n",
      "Epoch 2/30\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 0.0035 - val_loss: 0.0027\n",
      "Epoch 3/30\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.0015 - val_loss: 5.9458e-04\n",
      "Epoch 4/30\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.0013 - val_loss: 8.5383e-04\n",
      "Epoch 5/30\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 6/30\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.0011 - val_loss: 4.0919e-04\n",
      "Epoch 7/30\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 8/30\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.0010 - val_loss: 5.0108e-04\n",
      "Epoch 9/30\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.0010 - val_loss: 0.0018\n",
      "Epoch 10/30\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 9.9731e-04 - val_loss: 0.0011\n",
      "Epoch 11/30\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.0010 - val_loss: 4.0717e-04\n",
      "Epoch 12/30\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 9.5036e-04 - val_loss: 4.4279e-04\n",
      "Epoch 13/30\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 9.5686e-04 - val_loss: 5.7200e-04\n",
      "Epoch 14/30\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 9.6445e-04 - val_loss: 5.0026e-04\n",
      "Epoch 15/30\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 9.1730e-04 - val_loss: 6.8343e-04\n",
      "Epoch 16/30\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 8.9485e-04 - val_loss: 4.3018e-04\n",
      "Epoch 17/30\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 8.9559e-04 - val_loss: 6.0297e-04\n",
      "Epoch 18/30\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 8.9646e-04 - val_loss: 0.0012\n",
      "Epoch 19/30\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 8.9098e-04 - val_loss: 6.5095e-04\n",
      "Epoch 20/30\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 8.8910e-04 - val_loss: 6.5503e-04\n",
      "Epoch 21/30\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 8.5397e-04 - val_loss: 3.8397e-04\n",
      "Epoch 22/30\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 8.4551e-04 - val_loss: 0.0010\n",
      "Epoch 23/30\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 8.4117e-04 - val_loss: 4.6147e-04\n",
      "Epoch 24/30\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 8.0670e-04 - val_loss: 7.1046e-04\n",
      "Epoch 25/30\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 8.1070e-04 - val_loss: 2.8807e-04\n",
      "Epoch 26/30\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 8.5845e-04 - val_loss: 3.9035e-04\n",
      "Epoch 27/30\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 8.3042e-04 - val_loss: 6.8369e-04\n",
      "Epoch 28/30\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 7.8774e-04 - val_loss: 4.3709e-04\n",
      "Epoch 29/30\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 7.8180e-04 - val_loss: 3.6128e-04\n",
      "Epoch 30/30\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 7.7492e-04 - val_loss: 3.7101e-04\n",
      "16/16 [==============================] - 0s 4ms/step\n",
      "Best MSE:  81631407612725.92\n",
      "Best Params:  {'units': 128, 'epochs': 30, 'batch_size': 32}\n"
     ]
    }
   ],
   "source": [
    "bestModel,bestHistory = gridSearch([32, 64, 128], [10, 20, 30], [16, 32, 64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def trainModel(model, X_train, Y_train,epochs=50, batch_size=32):\n",
    "#     with tf.device('/device:GPU:0'):\n",
    "#         train_history = model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size, validation_split=0.1, shuffle=False)\n",
    "#     return train_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_history = trainModel(model, X_train, Y_train,epochs=20, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print history data\n",
    "plt.plot(bestHistory.history['loss'], label='loss')\n",
    "plt.plot(bestHistory.history['val_loss'], label='validation loss')\n",
    "plt.legend()\n",
    "plt.title(\"Training Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 6ms/step - loss: 8.1831e-04\n",
      "MSE on test:  0.000818310072645545\n"
     ]
    }
   ],
   "source": [
    "# Total Mean Squared Error for test\n",
    "mse = bestModel.evaluate(X_test, Y_test)\n",
    "print(\"MSE on test: \", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, data):\n",
    "    with tf.device('/device:GPU:0'):\n",
    "        last_n_days = data[-numberOfInputDays:]\n",
    "        last_n_days = last_n_days.reshape((1, numberOfInputDays, len(cols)))\n",
    "        prediction = model.predict(last_n_days)\n",
    "        real_predicted_price = scaler.inverse_transform(prediction)\n",
    "    return real_predicted_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 45ms/step\n"
     ]
    }
   ],
   "source": [
    "predicted_price = predict(bestModel, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Price:  [[1.7488380e+02 1.7721638e+02 1.7328308e+02 1.7578065e+02 1.7324110e+02\n",
      "  6.0518684e+07]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicted Price: \", predicted_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "bestModel.save('task2.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
